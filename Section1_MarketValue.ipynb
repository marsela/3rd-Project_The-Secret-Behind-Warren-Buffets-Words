{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Section I - Market Value Predicions\n",
    "\n",
    "### Filter Methods\n",
    "\n",
    "#### Part A -  Feature Extraction\n",
    "The following feature extraction stragetices   \n",
    "\n",
    "* **Principal Component Analysis** — In PCA, new independent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Annual reports into a \"Bag of Words\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n"
     ]
    }
   ],
   "source": [
    "############################## SCRAPE FROM WEB AND APPEND TXT FILES\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "filename = 'complete.csv'\n",
    "\n",
    "def appender(_row):\n",
    "    with open(filename, \"a+\", newline='', encoding='utf-8', errors='ignore') as out:\n",
    "        writer = csv.writer(out)\n",
    "        writer.writerow(_row)\n",
    "    return True\n",
    "\n",
    "appender([\"Year\", \"Content\"])\n",
    "\n",
    "for year in range(1977, 2003 + 1):\n",
    "    print(year)\n",
    "    data = BeautifulSoup(requests.get(\"http://www.berkshirehathaway.com/letters/{}.html\".format(year)).content, 'html.parser')\n",
    "    data = data.find('body').get_text()\n",
    "    appender([year, data])\n",
    "\n",
    "for year in range(2004, 2016 + 1):\n",
    "    print(year)\n",
    "    appender([year, open(\"{}.txt\".format(year), encoding='utf-8', errors='ignore').read()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "['1965', 23.8, 49.5, 10.0, 20.3, -3.4, 1, 1, 4, -1]\n",
      "['1966', 20.3, -3.4, -11.7, 11.0, 13.3, 0, 0, 2, 2]\n",
      "['1967', 11.0, 13.3, 30.9, 19.0, 77.8, 1, 1, 3, 4]\n",
      "['1968', 19.0, 77.8, 11.0, 16.2, 19.4, 1, 1, 3, 3]\n",
      "['1969', 16.2, 19.4, -8.4, 12.0, -4.6, 1, 0, 2, -1]\n",
      "['1970', 12.0, -4.6, 3.9, 16.4, 80.5, 1, 1, 3, 4]\n",
      "['1971', 16.4, 80.5, 14.6, 21.7, 8.1, 1, 0, 4, 1]\n",
      "['1972', 21.7, 8.1, 18.9, 4.7, -2.5, 1, 1, 0, -1]\n",
      "['1973', 4.7, -2.5, -14.8, 5.5, -48.7, 1, 0, 1, -1]\n",
      "['1974', 5.5, -48.7, -26.4, 21.9, 2.5, 0, 0, 4, 0]\n",
      "['1975', 21.9, 2.5, 37.2, 59.3, 129.3, 1, 1, 4, 4]\n",
      "['1976', 59.3, 129.3, 23.6, 31.9, 46.8, 1, 1, 4, 4]\n",
      "['1977', 31.9, 46.8, -7.4, 24.0, 14.5, 1, 1, 4, 2]\n",
      "['1978', 24.0, 14.5, 6.4, 35.7, 102.5, 1, 1, 4, 4]\n",
      "['1979', 35.7, 102.5, 18.2, 19.3, 32.8, 0, 1, 3, 4]\n",
      "['1980', 19.3, 32.8, 32.3, 31.4, 31.8, 1, 1, 4, 4]\n",
      "['1981', 31.4, 31.8, -5.0, 40.0, 38.4, 1, 1, 4, 4]\n",
      "['1982', 40.0, 38.4, 21.4, 32.3, 69.0, 1, 1, 4, 4]\n",
      "['1983', 32.3, 69.0, 22.4, 13.6, -2.7, 1, 0, 2, -1]\n",
      "['1984', 13.6, -2.7, 6.1, 48.2, 93.7, 1, 1, 4, 4]\n",
      "['1985', 48.2, 93.7, 31.6, 26.1, 14.2, 1, 0, 4, 2]\n",
      "['1986', 26.1, 14.2, 18.6, 19.5, 4.6, 1, 0, 3, 0]\n",
      "['1987', 19.5, 4.6, 5.1, 20.1, 59.3, 1, 1, 4, 4]\n",
      "['1988', 20.1, 59.3, 16.6, 44.4, 84.6, 1, 1, 4, 4]\n",
      "['1989', 44.4, 84.6, 31.7, 7.4, -23.1, 1, 0, 1, -1]\n",
      "['1990', 7.4, -23.1, -3.1, 39.6, 35.6, 1, 1, 4, 4]\n",
      "['1991', 39.6, 35.6, 30.5, 20.3, 29.8, 1, 1, 4, 4]\n",
      "['1992', 20.3, 29.8, 7.6, 14.3, 38.9, 1, 1, 2, 4]\n",
      "['1993', 14.3, 38.9, 10.1, 13.9, 25.0, 1, 1, 2, 4]\n",
      "['1994', 13.9, 25.0, 1.3, 43.1, 57.4, 1, 1, 4, 4]\n",
      "['1995', 43.1, 57.4, 37.6, 31.8, 6.2, 1, 0, 4, 1]\n",
      "['1996', 31.8, 6.2, 23.0, 34.1, 34.9, 1, 1, 4, 4]\n",
      "['1997', 34.1, 34.9, 33.4, 48.3, 52.2, 1, 1, 4, 4]\n",
      "['1998', 48.3, 52.2, 28.6, 0.5, -19.9, 0, 0, 0, -1]\n",
      "['1999', 0.5, -19.9, 21.0, 6.5, 26.6, 1, 1, 1, 4]\n",
      "['2000', 6.5, 26.6, -9.1, -6.2, 6.5, 1, 1, -1, 1]\n",
      "['2001', -6.2, 6.5, -11.9, 10.0, -3.8, 1, 1, 1, -1]\n",
      "['2002', 10.0, -3.8, -22.1, 21.0, 15.8, 0, 0, 4, 3]\n",
      "['2003', 21.0, 15.8, 28.7, 10.5, 4.3, 0, 0, 2, 0]\n",
      "['2004', 10.5, 4.3, 10.9, 6.4, 0.8, 1, 0, 1, 0]\n",
      "['2005', 6.4, 0.8, 4.9, 18.4, 24.1, 1, 1, 3, 4]\n",
      "['2006', 18.4, 24.1, 15.8, 11.0, 28.7, 1, 1, 2, 4]\n",
      "['2007', 11.0, 28.7, 5.5, -9.6, -31.8, 1, 1, -1, -1]\n",
      "['2008', -9.6, -31.8, -37.0, 19.8, 2.7, 0, 0, 3, 0]\n",
      "['2009', 19.8, 2.7, 26.5, 13.0, 21.4, 0, 1, 2, 4]\n",
      "['2010', 13.0, 21.4, 15.1, 4.6, -4.7, 1, 0, 0, -1]\n",
      "['2011', 4.6, -4.7, 2.1, 14.4, 16.8, 0, 1, 2, 3]\n",
      "['2012', 14.4, 16.8, 16.0, 18.2, 32.7, 0, 1, 3, 4]\n",
      "['2013', 18.2, 32.7, 32.4, 8.3, 27.0, 0, 1, 1, 4]\n",
      "['2014', 8.3, 27.0, 13.7, 6.4, -12.5, 1, 0, 1, -1]\n",
      "['2015', 6.4, -12.5, 1.4, 10.7, 23.4, 0, 1, 2, 4]\n",
      "['2016', 10.7, 23.4, 12.0]\n"
     ]
    }
   ],
   "source": [
    "########### Format and Create Response Variable\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "def process_data(data):\n",
    "    _step_1_data = []\n",
    "    for ind, row in enumerate(data):\n",
    "        try:\n",
    "            row += data[ind + 1][1:3]\n",
    "            _step_1_data.append(row)\n",
    "        except:\n",
    "            _step_1_data.append(row)\n",
    "\n",
    "    _step_2_data = []\n",
    "    for ind, r in enumerate(_step_1_data):\n",
    "        try:\n",
    "            if _step_1_data[ind + 1][1] >= _step_1_data[ind + 1][3]:\n",
    "                r.append(1)\n",
    "            else:\n",
    "                r.append(0)\n",
    "\n",
    "            if _step_1_data[ind + 1][2] >= _step_1_data[ind + 1][3]:\n",
    "                r.append(1)\n",
    "            else:\n",
    "                r.append(0)\n",
    "\n",
    "            _step_2_data.append(r)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            _step_2_data.append(r)\n",
    "\n",
    "    _step_3_data = []\n",
    "\n",
    "    for ind, r in enumerate(_step_2_data):\n",
    "        try:\n",
    "            r.append(calculate_val(_step_2_data[ind + 1][1]))\n",
    "            r.append(calculate_val(_step_2_data[ind + 1][2]))\n",
    "            _step_3_data.append(r)\n",
    "        except:\n",
    "            _step_3_data.append(r)\n",
    "\n",
    "    return _step_3_data\n",
    "\n",
    "\n",
    "def calculate_val(v):\n",
    "    if v < 0:\n",
    "        return -1\n",
    "    elif 0 < v < 5:\n",
    "        return 0\n",
    "    elif 5 < v < 10.001:\n",
    "        return 1\n",
    "    elif 10.001 < v < 15:\n",
    "        return 2\n",
    "    elif 15 < v < 20:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_name = 'return.csv'\n",
    "\n",
    "    data = []\n",
    "    # load the csv file\n",
    "    for row in csv.reader(open(file_name)):\n",
    "        #print(row)\n",
    "        data.append(row)\n",
    "    # remove the header\n",
    "    header = data[0]\n",
    "    valid_data = []\n",
    "    # convert the string type data into float for processing\n",
    "    for row in data[1:]:\n",
    "        _r = [row[0]]\n",
    "        _r += [float(x) for x in row[1:]]\n",
    "        valid_data.append(_r)\n",
    "    # call the working function and pint the results\n",
    "    for r in process_data(valid_data):\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "col_name = ['Year',\t'BV Return',\t'MV Return',\t'S&P',\t'NextYearBVReturn',\t'NextYearMVReturn',\t'BVBeatS&P',\t'MVBeatS&P',\t'Performance_Category_BV',\t'Performance_Category_MV']\n",
    "dataset = pd.DataFrame(valid_data,columns=col_name)\n",
    "dataset.to_csv('return_plus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "########### BEGIN NATURAL LANGUAGE PROCESSING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Import data\n",
    "dataset = pd.read_csv('complete.csv')\n",
    "target = pd.read_csv('return_plus.csv') #col = 8, 9 <-original 9 and 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\volak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Cleaning the text\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_rows = dataset.shape[0]\n",
    "\n",
    "\n",
    "# Create a For Loop to do this to all reviews \n",
    "corpus = []\n",
    "for i in range (0, n_rows):\n",
    "    review= re.sub('[^a-zA-Z]',' ', dataset['Content'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split() \n",
    "    ps=PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review) \n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of Words Model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_prep = cv.fit_transform(corpus).toarray()\n",
    "X = X_prep[:-1,:] #Because we are predicting next year we do not yet have results for the last row, but can use this as a predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Response / Target Feature\n",
    "target.columns\n",
    "'''  \n",
    "The ones we will run are 'MVBeatS&P'\n",
    "                         'BVBeatS&P' \n",
    "                         'NextYearMVReturn'\n",
    "                         'NextYearBVReturn'\n",
    "                         \n",
    "'''\n",
    "response = target['MVBeatS&P']\n",
    "response = pd.DataFrame(response)\n",
    "y = response.iloc[12:-1,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state = 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Classification ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "######################################### Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "0.75\n",
      "0.75\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# Get the Accuracy, Precision and Recall Score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "############## Predicting Next Years Results\n",
    "X_2017 = X_prep[39:,:]\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_2017)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=2000, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 2000, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n",
      "0.8\n",
      "1.0\n",
      "0.888888888889\n"
     ]
    }
   ],
   "source": [
    "# Get the Accuracy, Precision and Recall Score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "############## Predicting Next Years Results\n",
    "X_2017 = X_prep[39:,:]\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_2017)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################ Artifical Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### Setting up the Layers of the Neural Network\n",
    "#Set the number of features\n",
    "n_cols = X_train.shape[1]\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 1000, kernel_initializer = 'uniform', activation = 'relu', input_dim = n_cols))\n",
    "classifier.add(Dropout(p = 0.1))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 1000, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(p = 0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 4s - loss: 3.7153 - acc: 0.6087     \n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 3s - loss: 3.8438 - acc: 0.6522     \n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 3s - loss: 3.7126 - acc: 0.6522     \n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 3s - loss: 3.6403 - acc: 0.6957     \n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 3s - loss: 3.6318 - acc: 0.6957     \n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 3s - loss: 3.6341 - acc: 0.6087     \n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 3s - loss: 3.6224 - acc: 0.6957     \n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 3s - loss: 3.6453 - acc: 0.6957     \n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 3s - loss: 3.6096 - acc: 0.6957     \n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 3s - loss: 3.6318 - acc: 0.6522     \n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 3s - loss: 3.6234 - acc: 0.6522     \n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 3s - loss: 3.6206 - acc: 0.6957     \n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 3s - loss: 3.6163 - acc: 0.6957     \n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 3s - loss: 3.6170 - acc: 0.6957     \n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 3s - loss: 3.6271 - acc: 0.6522     \n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 3s - loss: 3.6180 - acc: 0.6957     \n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 3s - loss: 3.6136 - acc: 0.6957     \n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 3s - loss: 3.6135 - acc: 0.6957     \n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 3s - loss: 3.6134 - acc: 0.6957     \n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 3s - loss: 3.6185 - acc: 0.6957     \n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 3s - loss: 3.6130 - acc: 0.6522     \n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 3s - loss: 3.6147 - acc: 0.6957     \n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 3s - loss: 3.6194 - acc: 0.6522     \n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 3s - loss: 3.6215 - acc: 0.7391     \n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 3s - loss: 3.6211 - acc: 0.6957     \n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 3s - loss: 3.6207 - acc: 0.6957     \n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 3s - loss: 3.6127 - acc: 0.6957     \n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 3s - loss: 3.6202 - acc: 0.6957     \n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 3s - loss: 3.6191 - acc: 0.6957     \n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 3s - loss: 3.6116 - acc: 0.6522     \n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 3s - loss: 3.6142 - acc: 0.6957     \n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 3s - loss: 3.6152 - acc: 0.6957     \n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 3s - loss: 3.6121 - acc: 0.6957     \n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 3s - loss: 3.6182 - acc: 0.6957     \n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 3s - loss: 3.6087 - acc: 0.6957     \n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 3s - loss: 3.6114 - acc: 0.6957     \n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 3s - loss: 3.6154 - acc: 0.6957     \n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 3s - loss: 3.6123 - acc: 0.6957     \n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 3s - loss: 3.6140 - acc: 0.6957     \n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 3s - loss: 3.6116 - acc: 0.6957     \n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 3s - loss: 3.6124 - acc: 0.6522     \n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 3s - loss: 3.6156 - acc: 0.6957     \n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 3s - loss: 3.6106 - acc: 0.6522     \n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 3s - loss: 3.6135 - acc: 0.6957     \n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 3s - loss: 3.6152 - acc: 0.6522     \n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 3s - loss: 3.6122 - acc: 0.6957     \n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 3s - loss: 3.6165 - acc: 0.6522     \n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 3s - loss: 3.6133 - acc: 0.7391     \n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 3s - loss: 3.6147 - acc: 0.6522     \n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 3s - loss: 3.6131 - acc: 0.6957     \n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 3s - loss: 3.6105 - acc: 0.6522     \n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 3s - loss: 3.6121 - acc: 0.6522     \n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 3s - loss: 3.6170 - acc: 0.6522     \n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 3s - loss: 3.6145 - acc: 0.6957     \n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 3s - loss: 3.6098 - acc: 0.6957     \n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 3s - loss: 3.6134 - acc: 0.6957     \n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 3s - loss: 3.6112 - acc: 0.6957     \n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 3s - loss: 3.6084 - acc: 0.6957     \n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 3s - loss: 3.6089 - acc: 0.6957     \n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 3s - loss: 3.6140 - acc: 0.6957     \n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 3s - loss: 3.6034 - acc: 0.6957     \n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 3s - loss: 3.6119 - acc: 0.6522     \n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 3s - loss: 3.6156 - acc: 0.6957     \n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 3s - loss: 3.6211 - acc: 0.6957     \n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 4s - loss: 3.6138 - acc: 0.6522     \n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 3s - loss: 3.6138 - acc: 0.6957     \n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 3s - loss: 3.6112 - acc: 0.6957     \n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 3s - loss: 3.6157 - acc: 0.7391     \n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 3s - loss: 3.6171 - acc: 0.6957     \n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 3s - loss: 3.6084 - acc: 0.6522     \n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 3s - loss: 3.6118 - acc: 0.6957     \n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 3s - loss: 3.6180 - acc: 0.6957     \n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 3s - loss: 3.6085 - acc: 0.6957     \n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 3s - loss: 3.6150 - acc: 0.6957     \n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 3s - loss: 3.6111 - acc: 0.6957     \n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 4s - loss: 3.6119 - acc: 0.6957     \n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 3s - loss: 3.6135 - acc: 0.6957     \n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 3s - loss: 3.6126 - acc: 0.6957     \n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 4s - loss: 3.6108 - acc: 0.6957     \n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 3s - loss: 3.6129 - acc: 0.6957     \n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 3s - loss: 3.6107 - acc: 0.6957     \n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 3s - loss: 3.6115 - acc: 0.6957     \n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 3s - loss: 3.6135 - acc: 0.6957     \n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 3s - loss: 3.6112 - acc: 0.6957     \n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 3s - loss: 3.6135 - acc: 0.6957     \n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 3s - loss: 3.6109 - acc: 0.6957     \n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 3s - loss: 3.6081 - acc: 0.6957     \n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 3s - loss: 3.6095 - acc: 0.6957     \n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 3s - loss: 3.6070 - acc: 0.6957     \n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 4s - loss: 3.6137 - acc: 0.6957     \n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s - loss: 3.6145 - acc: 0.6957     \n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 3s - loss: 3.6150 - acc: 0.6957     \n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 3s - loss: 3.6185 - acc: 0.6957     \n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 3s - loss: 3.6122 - acc: 0.6957     \n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 3s - loss: 3.6114 - acc: 0.6957     \n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 3s - loss: 3.6040 - acc: 0.6957     \n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 3s - loss: 3.6128 - acc: 0.6957     \n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 3s - loss: 3.6109 - acc: 0.6957     \n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 3s - loss: 3.6069 - acc: 0.6957     \n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 3s - loss: 3.6085 - acc: 0.6957     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fffd905c18>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 2, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n",
      "0.8\n",
      "1.0\n",
      "0.888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]]\n"
     ]
    }
   ],
   "source": [
    "############## Predicting Next Years Results\n",
    "X_2017 = X_prep[39:,:]\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_2017)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Regression ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Change to regression response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = target['NextYearMVReturn']\n",
    "response = pd.DataFrame(response)\n",
    "y = response.iloc[12:-1,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################# SPLIT TRAINING AND TESTING SET\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################### REGRESSION \n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.31710063436e+13\n",
      "1.27455304032e+27\n",
      "3.57008829067e+13\n"
     ]
    }
   ],
   "source": [
    "############## Calculating Errors\n",
    "#Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mae)\n",
    "\n",
    "# Mean Square Error & ROOT RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "############################### RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 1000, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0177835913\n",
      "531.866176127\n",
      "23.0622240065\n"
     ]
    }
   ],
   "source": [
    "#Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mae)\n",
    "\n",
    "# Mean Square Error & ROOT RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.84444619]\n"
     ]
    }
   ],
   "source": [
    "############## Predicting Next Years Results\n",
    "X_2017 = X_prep[39:,:]\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_2017)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "############################### Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1209994918\n",
      "682.625037107\n",
      "26.1270939277\n"
     ]
    }
   ],
   "source": [
    "#Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mae)\n",
    "\n",
    "# Mean Square Error & ROOT RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15.0091575]\n"
     ]
    }
   ],
   "source": [
    "############## Predicting Next Years Results\n",
    "X_2017 = X_prep[39:,:]\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_2017)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "###############################  Fitting XGBoost to the Training set\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.23125\n",
      "4223.303125\n",
      "64.9869458045\n"
     ]
    }
   ],
   "source": [
    "#Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mae)\n",
    "\n",
    "# Mean Square Error & ROOT RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15.0091575]\n"
     ]
    }
   ],
   "source": [
    "############## Predicting Next Years Results\n",
    "X_2017 = X_prep[39:,:]\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_2017)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################  Neural Network\n",
    "########## NEURAL NETWORKS Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1000, input_dim=8084, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  import sys\n",
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1000, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"normal\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Set the number of features\n",
    "n_cols = X_train.shape[1]\n",
    "# Initialising the ANN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(output_dim = 1000, init = 'normal', activation = 'relu', input_dim = n_cols))\n",
    "model.add(Dropout(p=0.1))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(output_dim = 1000, init = 'normal', activation = 'relu'))\n",
    "model.add(Dropout(p=0.1))\n",
    "\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(output_dim = 1, init = 'normal'))\n",
    "\"\"\"No activation function is used for the output layer because it is a regression problem\"\"\"\n",
    "\n",
    "# Compiling the ANN\n",
    "model.compile(optimizer = 'adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\volak\\Anaconda3\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 8s - loss: 59.7345     \n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 6s - loss: 48.9156     \n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 6s - loss: 25.4817     \n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 6s - loss: 34.9065     \n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 6s - loss: 24.5166     \n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 6s - loss: 22.9411     \n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 6s - loss: 22.5987     \n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 6s - loss: 24.4795     \n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 6s - loss: 19.0137     \n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 6s - loss: 15.5924     \n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 6s - loss: 17.0916     \n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 6s - loss: 20.1780     \n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 6s - loss: 15.5812     \n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 6s - loss: 15.4241     \n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 6s - loss: 15.1158     \n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 6s - loss: 11.8401     \n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 6s - loss: 13.9215     \n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 7s - loss: 14.2632     \n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 7s - loss: 14.2328     \n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 6s - loss: 12.4659     \n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 6s - loss: 14.6339     \n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 6s - loss: 16.5430     \n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 6s - loss: 13.7310     \n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 6s - loss: 9.6192     \n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 6s - loss: 9.5854     \n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 6s - loss: 8.5889     \n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 6s - loss: 11.7389     \n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 6s - loss: 12.1753     \n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 6s - loss: 9.2237     \n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 6s - loss: 14.5255     \n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 6s - loss: 8.3419     \n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 6s - loss: 8.8165     \n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 6s - loss: 12.2168     \n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 6s - loss: 9.6519      \n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 6s - loss: 13.6365     \n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 6s - loss: 12.8327     \n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 6s - loss: 10.0927     \n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 6s - loss: 12.1074     \n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 6s - loss: 9.5319     \n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 6s - loss: 14.5022     \n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 6s - loss: 11.3667     \n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 6s - loss: 8.8435     \n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 6s - loss: 9.1417     \n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 6s - loss: 8.3761     \n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 6s - loss: 8.4280     \n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 6s - loss: 10.1864    \n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 6s - loss: 12.7247     \n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 6s - loss: 8.8318     \n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 6s - loss: 12.4817     \n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 6s - loss: 8.4183     \n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 6s - loss: 6.9916     \n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 7s - loss: 13.1594     \n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 7s - loss: 11.2619     \n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 6s - loss: 8.4878     \n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 6s - loss: 11.0821     \n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 6s - loss: 9.3813     \n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 6s - loss: 8.5693     \n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 6s - loss: 8.3954     \n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 6s - loss: 8.8851     \n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 6s - loss: 8.8714     \n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 6s - loss: 10.7201    \n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 6s - loss: 11.7900     \n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 7s - loss: 9.4983     \n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 6s - loss: 8.1048     \n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 6s - loss: 6.1055     \n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 6s - loss: 7.6975     \n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 6s - loss: 8.2393     \n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 6s - loss: 9.1609     \n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 6s - loss: 8.2625     \n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 7s - loss: 9.9792     \n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 6s - loss: 6.4855     \n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 6s - loss: 11.3378     \n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 6s - loss: 10.2714     \n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 7s - loss: 6.9772     \n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 6s - loss: 6.6492     \n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 6s - loss: 8.3924     \n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 7s - loss: 9.2184     \n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 7s - loss: 9.2704     \n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 7s - loss: 9.9840     \n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 7s - loss: 8.8348     \n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 6s - loss: 6.3279     \n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 6s - loss: 8.2974     \n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 6s - loss: 8.3985     \n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 6s - loss: 7.7660     \n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 6s - loss: 8.7331     \n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 6s - loss: 8.3801     \n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 6s - loss: 9.1114     \n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 6s - loss: 7.7600     \n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 6s - loss: 6.2603     \n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 6s - loss: 11.8478     \n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 6s - loss: 8.5095     \n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 7s - loss: 6.6600     \n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 7s - loss: 7.5705     \n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 7s - loss: 7.4156     \n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 7s - loss: 9.0575     \n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 7s - loss: 7.1705     \n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 7s - loss: 8.9295     \n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 6s - loss: 10.1270     \n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 6s - loss: 8.6645     \n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 6s - loss: 7.2557     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ff9c4a7ba8>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train, batch_size = 1, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.6403051198\n",
      "776.454885438\n",
      "27.864940076\n"
     ]
    }
   ],
   "source": [
    "#Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mae)\n",
    "\n",
    "# Mean Square Error & ROOT RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15.0091575]\n"
     ]
    }
   ],
   "source": [
    "############## Predicting Next Years Results\n",
    "X_2017 = X_prep[39:,:]\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_2017)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
